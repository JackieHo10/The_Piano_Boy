{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"    \n",
    "\n",
    "    network_input, network_output = prepare_sequences(get_notes())\n",
    "    validate_input, validate_output = prepare_sequences(get_notes(\"test\"))\n",
    "    model = create_network(network_input)\n",
    "\n",
    "    train(model, network_input, network_output, validate_input, validate_output)\n",
    "    \n",
    "    \n",
    "def merge_notes(notes_dict, max_offset):\n",
    "            \n",
    "    ret = np.array([])\n",
    "    for i in np.arange(0, max_offset, 0.5):\n",
    "        pitches = np.zeros(88)\n",
    "        if i in notes_dict:            \n",
    "            for element in notes_dict[i]:            \n",
    "                if isinstance(element, note.Note):\n",
    "                    pitches[element.pitch.midi-21] = 1\n",
    "                else:\n",
    "                    for p in element.pitches:\n",
    "                        pitches[p.midi-21] = 1    \n",
    "        ret = np.append(ret, pitches)\n",
    "    return ret\n",
    "    \n",
    "\n",
    "def get_notes(folder=\"midi_songs\"):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = np.array([])\n",
    "\n",
    "    for file in glob.glob(\"{}/*.mid\".format(folder)):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        notes_dict = {}\n",
    "        max_offset = 0\n",
    "        for element in notes_to_parse:        \n",
    "            if isinstance(element, note.Note) or isinstance(element, chord.Chord):  \n",
    "                if element.offset not in notes_dict:\n",
    "                    notes_dict[element.offset] = []\n",
    "                notes_dict[element.offset].append(element)\n",
    "                max_offset = element.offset    \n",
    "        ret = merge_notes(notes_dict, max_offset)\n",
    "        #print(len(ret))\n",
    "        notes = np.append(notes, ret)\n",
    "        #print(len(notes))\n",
    "    row = notes.size / 88\n",
    "    notes = notes.reshape(int(row), 88)\n",
    "    #with open('data/notes', 'wb') as filepath:\n",
    "        #pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 40\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append(sequence_in)\n",
    "        network_output.append(sequence_out)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    #print(n_patterns)\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 88))\n",
    "    network_output = np.reshape(network_output, (n_patterns, 88))\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def create_network(network_input):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(88))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    #model.add(Activation('softmax'))\n",
    "    #model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "def train(model, network_input, network_output, validate_input, validate_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    #print(network_input.shape)\n",
    "    #print(network_output.shape)\n",
    "    model.fit(network_input, network_output, \n",
    "              validation_data=(validate_input,validate_output), \n",
    "              epochs=200, batch_size=64, \n",
    "              callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing midi_songs/Ff7-Cinco.mid\n",
      "Parsing midi_songs/waltz_de_choco.mid\n",
      "Parsing midi_songs/Ff4-BattleLust.mid\n",
      "Parsing midi_songs/dontbeafraid.mid\n",
      "Parsing midi_songs/electric_de_chocobo.mid\n",
      "Parsing midi_songs/costadsol.mid\n",
      "Parsing midi_songs/Ff7-Jenova_Absolute.mid\n",
      "Parsing midi_songs/tifap.mid\n",
      "Parsing midi_songs/Still_Alive-1.mid\n",
      "Parsing midi_songs/bcm.mid\n",
      "Parsing midi_songs/ff7-mainmidi.mid\n",
      "Parsing midi_songs/ultros.mid\n",
      "Parsing midi_songs/0fithos.mid\n",
      "Parsing midi_songs/mining.mid\n",
      "Parsing midi_songs/Ff7-One_Winged.mid\n",
      "Parsing midi_songs/FFIX_Piano.mid\n",
      "Parsing midi_songs/balamb.mid\n",
      "Parsing midi_songs/caitsith.mid\n",
      "Parsing midi_songs/path_of_repentance.mid\n",
      "Parsing midi_songs/ff1battp.mid\n",
      "Parsing midi_songs/Finalfantasy6fanfarecomplete.mid\n",
      "Parsing midi_songs/Oppressed.mid\n",
      "Parsing midi_songs/relmstheme-piano.mid\n",
      "Parsing midi_songs/ff4-fight1.mid\n",
      "Parsing midi_songs/Finalfantasy5gilgameshp.mid\n",
      "Parsing midi_songs/FF4.mid\n",
      "Parsing midi_songs/Final_Fantasy_Matouyas_Cave_Piano.mid\n",
      "Parsing midi_songs/Eternal_Harvest.mid\n",
      "Parsing midi_songs/thoughts.mid\n",
      "Parsing midi_songs/ff7themep.mid\n",
      "Parsing midi_songs/goldsaucer.mid\n",
      "Parsing midi_songs/Gold_Silver_Rival_Battle.mid\n",
      "Parsing midi_songs/Fyw_piano.mid\n",
      "Parsing midi_songs/EyesOnMePiano.mid\n",
      "Parsing midi_songs/BlueStone_LastDungeon.mid\n",
      "Parsing midi_songs/ff4-airship.mid\n",
      "Parsing midi_songs/sobf.mid\n",
      "Parsing midi_songs/ff4pclov.mid\n",
      "Parsing midi_songs/z_aeristhemepiano.mid\n",
      "Parsing midi_songs/HighwindTakestotheSkies.mid\n",
      "Parsing midi_songs/ahead_on_our_way_piano.mid\n",
      "Parsing midi_songs/Suteki_Da_Ne_(Piano_Version).mid\n",
      "Parsing midi_songs/figaro.mid\n",
      "Parsing midi_songs/FFX_-_Ending_Theme_(Piano_Version)_-_by_Angel_FF.mid\n",
      "Parsing midi_songs/Kingdom_Hearts_Traverse_Town.mid\n",
      "Parsing midi_songs/cosmo.mid\n",
      "Parsing midi_songs/8.mid\n",
      "Parsing midi_songs/FFIII_Edgar_And_Sabin_Piano.mid\n",
      "Parsing midi_songs/FF3_Battle_(Piano).mid\n",
      "Parsing midi_songs/Zelda_Overworld.mid\n",
      "Parsing midi_songs/braska.mid\n",
      "Parsing midi_songs/sandy.mid\n",
      "Parsing midi_songs/ff4_piano_collections-main_theme.mid\n",
      "Parsing midi_songs/JENOVA.mid\n",
      "Parsing midi_songs/ViviinAlexandria.mid\n",
      "Parsing midi_songs/ff11_awakening_piano.mid\n",
      "Parsing midi_songs/Fiend_Battle_(Piano).mid\n",
      "Parsing midi_songs/Fierce_Battle_(Piano).mid\n",
      "Parsing midi_songs/great_war.mid\n",
      "Parsing midi_songs/FF6epitaph_piano.mid\n",
      "Parsing midi_songs/dayafter.mid\n",
      "Parsing midi_songs/ff6shap.mid\n",
      "Parsing midi_songs/VincentPiano.mid\n",
      "Parsing midi_songs/Life_Stream.mid\n",
      "Parsing midi_songs/FFIXQuMarshP.mid\n",
      "Parsing midi_songs/fortresscondor.mid\n",
      "Parsing midi_songs/FFVII_BATTLE.mid\n",
      "Parsing midi_songs/FF3_Third_Phase_Final_(Piano).mid\n",
      "Parsing midi_songs/AT.mid\n",
      "Parsing midi_songs/In_Zanarkand.mid\n",
      "Parsing midi_songs/ff8-lfp.mid\n",
      "Parsing midi_songs/Cids.mid\n",
      "Parsing midi_songs/sera_.mid\n",
      "Parsing midi_songs/FF8_Shuffle_or_boogie_pc.mid\n",
      "Parsing midi_songs/Rachel_Piano_tempofix.mid\n",
      "Parsing midi_songs/gerudo.mid\n",
      "Parsing midi_songs/ff4-town.mid\n",
      "Parsing midi_songs/DOS.mid\n",
      "Parsing midi_songs/OTD5YA.mid\n",
      "Parsing midi_songs/redwings.mid\n",
      "Parsing midi_songs/pkelite4.mid\n",
      "Parsing midi_songs/tpirtsd-piano.mid\n",
      "Parsing midi_songs/rufus.mid\n",
      "Parsing midi_songs/roseofmay-piano.mid\n",
      "Parsing midi_songs/traitor.mid\n",
      "Parsing midi_songs/Rydia_pc.mid\n",
      "Parsing midi_songs/ultimafro.mid\n",
      "Parsing midi_songs/decisive.mid\n",
      "Parsing midi_songs/Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
      "Parsing midi_songs/thenightmarebegins.mid\n",
      "Parsing test/Kingdom_Hearts_Dearly_Beloved.mid\n",
      "Parsing test/lurk_in_dark.mid\n",
      "Train on 46370 samples, validate on 460 samples\n",
      "Epoch 1/200\n",
      "46370/46370 [==============================] - 76s 2ms/step - loss: 0.0808 - acc: 0.9824 - val_loss: 0.0511 - val_acc: 0.9921\n",
      "Epoch 2/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0720 - acc: 0.9838 - val_loss: 0.0481 - val_acc: 0.9921\n",
      "Epoch 3/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0691 - acc: 0.9835 - val_loss: 0.0467 - val_acc: 0.9921\n",
      "Epoch 4/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0639 - acc: 0.9840 - val_loss: 0.0469 - val_acc: 0.9921\n",
      "Epoch 5/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0603 - acc: 0.9842 - val_loss: 0.0454 - val_acc: 0.9921\n",
      "Epoch 6/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0580 - acc: 0.9844 - val_loss: 0.0457 - val_acc: 0.9921\n",
      "Epoch 7/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0560 - acc: 0.9847 - val_loss: 0.0474 - val_acc: 0.9921\n",
      "Epoch 8/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0540 - acc: 0.9850 - val_loss: 0.0449 - val_acc: 0.9921\n",
      "Epoch 9/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0520 - acc: 0.9854 - val_loss: 0.0444 - val_acc: 0.9921\n",
      "Epoch 10/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0501 - acc: 0.9857 - val_loss: 0.0479 - val_acc: 0.9921\n",
      "Epoch 11/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0481 - acc: 0.9861 - val_loss: 0.0452 - val_acc: 0.9921\n",
      "Epoch 12/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0462 - acc: 0.9864 - val_loss: 0.0450 - val_acc: 0.9920\n",
      "Epoch 13/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0444 - acc: 0.9868 - val_loss: 0.0459 - val_acc: 0.9920\n",
      "Epoch 14/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0423 - acc: 0.9872 - val_loss: 0.0458 - val_acc: 0.9920\n",
      "Epoch 15/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0405 - acc: 0.9876 - val_loss: 0.0452 - val_acc: 0.9920\n",
      "Epoch 16/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0387 - acc: 0.9880 - val_loss: 0.0482 - val_acc: 0.9919\n",
      "Epoch 17/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0369 - acc: 0.9884 - val_loss: 0.0495 - val_acc: 0.9919\n",
      "Epoch 18/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.0477 - val_acc: 0.9916\n",
      "Epoch 19/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0337 - acc: 0.9892 - val_loss: 0.0496 - val_acc: 0.9917\n",
      "Epoch 20/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0321 - acc: 0.9896 - val_loss: 0.0521 - val_acc: 0.9915\n",
      "Epoch 21/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0305 - acc: 0.9900 - val_loss: 0.0510 - val_acc: 0.9913\n",
      "Epoch 22/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0292 - acc: 0.9903 - val_loss: 0.0526 - val_acc: 0.9914\n",
      "Epoch 23/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0279 - acc: 0.9907 - val_loss: 0.0530 - val_acc: 0.9912\n",
      "Epoch 24/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0267 - acc: 0.9910 - val_loss: 0.0558 - val_acc: 0.9914\n",
      "Epoch 25/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0255 - acc: 0.9914 - val_loss: 0.0553 - val_acc: 0.9906\n",
      "Epoch 26/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0245 - acc: 0.9917 - val_loss: 0.0560 - val_acc: 0.9912\n",
      "Epoch 27/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0234 - acc: 0.9920 - val_loss: 0.0555 - val_acc: 0.9901\n",
      "Epoch 28/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0222 - acc: 0.9923 - val_loss: 0.0596 - val_acc: 0.9907\n",
      "Epoch 29/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0214 - acc: 0.9926 - val_loss: 0.0555 - val_acc: 0.9904\n",
      "Epoch 30/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.0583 - val_acc: 0.9915\n",
      "Epoch 31/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0198 - acc: 0.9931 - val_loss: 0.0650 - val_acc: 0.9913\n",
      "Epoch 32/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0191 - acc: 0.9934 - val_loss: 0.0618 - val_acc: 0.9900\n",
      "Epoch 33/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0182 - acc: 0.9937 - val_loss: 0.0631 - val_acc: 0.9912\n",
      "Epoch 34/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.0626 - val_acc: 0.9906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0172 - acc: 0.9940 - val_loss: 0.0641 - val_acc: 0.9906\n",
      "Epoch 36/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.0679 - val_acc: 0.9905\n",
      "Epoch 37/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0159 - acc: 0.9944 - val_loss: 0.0631 - val_acc: 0.9906\n",
      "Epoch 38/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0153 - acc: 0.9946 - val_loss: 0.0670 - val_acc: 0.9906\n",
      "Epoch 39/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0149 - acc: 0.9948 - val_loss: 0.0690 - val_acc: 0.9909\n",
      "Epoch 40/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0144 - acc: 0.9949 - val_loss: 0.0731 - val_acc: 0.9907\n",
      "Epoch 41/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0139 - acc: 0.9951 - val_loss: 0.0730 - val_acc: 0.9898\n",
      "Epoch 42/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0136 - acc: 0.9952 - val_loss: 0.0718 - val_acc: 0.9908\n",
      "Epoch 43/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0131 - acc: 0.9954 - val_loss: 0.0750 - val_acc: 0.9903\n",
      "Epoch 44/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 0.0720 - val_acc: 0.9910\n",
      "Epoch 45/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0124 - acc: 0.9956 - val_loss: 0.0752 - val_acc: 0.9908\n",
      "Epoch 46/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0119 - acc: 0.9958 - val_loss: 0.0712 - val_acc: 0.9895\n",
      "Epoch 47/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0770 - val_acc: 0.9899\n",
      "Epoch 48/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0114 - acc: 0.9959 - val_loss: 0.0791 - val_acc: 0.9898\n",
      "Epoch 49/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0111 - acc: 0.9961 - val_loss: 0.0782 - val_acc: 0.9902\n",
      "Epoch 50/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0743 - val_acc: 0.9906\n",
      "Epoch 51/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.0814 - val_acc: 0.9915\n",
      "Epoch 52/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0103 - acc: 0.9963 - val_loss: 0.0765 - val_acc: 0.9898\n",
      "Epoch 53/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0757 - val_acc: 0.9906\n",
      "Epoch 54/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.0784 - val_acc: 0.9891\n",
      "Epoch 55/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0097 - acc: 0.9966 - val_loss: 0.0762 - val_acc: 0.9903\n",
      "Epoch 56/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0094 - acc: 0.9967 - val_loss: 0.0839 - val_acc: 0.9899\n",
      "Epoch 57/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0783 - val_acc: 0.9900\n",
      "Epoch 58/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0091 - acc: 0.9968 - val_loss: 0.0818 - val_acc: 0.9891\n",
      "Epoch 59/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0851 - val_acc: 0.9908\n",
      "Epoch 60/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0087 - acc: 0.9969 - val_loss: 0.0793 - val_acc: 0.9904\n",
      "Epoch 61/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0085 - acc: 0.9970 - val_loss: 0.0814 - val_acc: 0.9908\n",
      "Epoch 62/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0875 - val_acc: 0.9897\n",
      "Epoch 63/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0083 - acc: 0.9971 - val_loss: 0.0788 - val_acc: 0.9894\n",
      "Epoch 64/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0831 - val_acc: 0.9901\n",
      "Epoch 65/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0079 - acc: 0.9972 - val_loss: 0.0797 - val_acc: 0.9909\n",
      "Epoch 66/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0834 - val_acc: 0.9904\n",
      "Epoch 67/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0077 - acc: 0.9973 - val_loss: 0.0862 - val_acc: 0.9904\n",
      "Epoch 68/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0839 - val_acc: 0.9905\n",
      "Epoch 69/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0867 - val_acc: 0.9897\n",
      "Epoch 70/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0880 - val_acc: 0.9899\n",
      "Epoch 71/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0909 - val_acc: 0.9905\n",
      "Epoch 72/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.0854 - val_acc: 0.9906\n",
      "Epoch 73/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0070 - acc: 0.9975 - val_loss: 0.0827 - val_acc: 0.9907\n",
      "Epoch 74/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0068 - acc: 0.9976 - val_loss: 0.0799 - val_acc: 0.9909\n",
      "Epoch 75/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0878 - val_acc: 0.9901\n",
      "Epoch 76/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0849 - val_acc: 0.9903\n",
      "Epoch 77/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0884 - val_acc: 0.9901\n",
      "Epoch 78/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0849 - val_acc: 0.9902\n",
      "Epoch 79/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0830 - val_acc: 0.9897\n",
      "Epoch 80/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0850 - val_acc: 0.9896\n",
      "Epoch 81/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0900 - val_acc: 0.9906\n",
      "Epoch 82/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0877 - val_acc: 0.9900\n",
      "Epoch 83/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0898 - val_acc: 0.9911\n",
      "Epoch 84/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0933 - val_acc: 0.9909\n",
      "Epoch 85/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0884 - val_acc: 0.9907\n",
      "Epoch 86/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0870 - val_acc: 0.9909\n",
      "Epoch 87/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0923 - val_acc: 0.9906\n",
      "Epoch 88/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0057 - acc: 0.9981 - val_loss: 0.0887 - val_acc: 0.9903\n",
      "Epoch 89/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0903 - val_acc: 0.9905\n",
      "Epoch 90/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0905 - val_acc: 0.9897\n",
      "Epoch 91/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0856 - val_acc: 0.9902\n",
      "Epoch 92/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0054 - acc: 0.9982 - val_loss: 0.0932 - val_acc: 0.9910\n",
      "Epoch 93/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0054 - acc: 0.9981 - val_loss: 0.0930 - val_acc: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0839 - val_acc: 0.9901\n",
      "Epoch 95/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0928 - val_acc: 0.9902\n",
      "Epoch 96/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0923 - val_acc: 0.9907\n",
      "Epoch 97/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0870 - val_acc: 0.9905\n",
      "Epoch 98/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0902 - val_acc: 0.9899\n",
      "Epoch 99/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0955 - val_acc: 0.9902\n",
      "Epoch 100/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0915 - val_acc: 0.9900\n",
      "Epoch 101/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0921 - val_acc: 0.9908\n",
      "Epoch 102/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0893 - val_acc: 0.9904\n",
      "Epoch 103/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0935 - val_acc: 0.9906\n",
      "Epoch 104/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0887 - val_acc: 0.9903\n",
      "Epoch 105/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0898 - val_acc: 0.9906\n",
      "Epoch 106/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0969 - val_acc: 0.9904\n",
      "Epoch 107/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0928 - val_acc: 0.9906\n",
      "Epoch 108/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.1003 - val_acc: 0.9909\n",
      "Epoch 109/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0903 - val_acc: 0.9902\n",
      "Epoch 110/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.0930 - val_acc: 0.9905\n",
      "Epoch 111/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0968 - val_acc: 0.9903\n",
      "Epoch 112/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0972 - val_acc: 0.9904\n",
      "Epoch 113/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0957 - val_acc: 0.9903\n",
      "Epoch 114/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0875 - val_acc: 0.9899\n",
      "Epoch 115/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0974 - val_acc: 0.9903\n",
      "Epoch 116/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0927 - val_acc: 0.9907\n",
      "Epoch 117/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0953 - val_acc: 0.9900\n",
      "Epoch 118/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.1000 - val_acc: 0.9905\n",
      "Epoch 119/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0934 - val_acc: 0.9907\n",
      "Epoch 120/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0960 - val_acc: 0.9905\n",
      "Epoch 121/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0973 - val_acc: 0.9903\n",
      "Epoch 122/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0975 - val_acc: 0.9910\n",
      "Epoch 123/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0989 - val_acc: 0.9904\n",
      "Epoch 124/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0983 - val_acc: 0.9909\n",
      "Epoch 125/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0967 - val_acc: 0.9911\n",
      "Epoch 126/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0937 - val_acc: 0.9902\n",
      "Epoch 127/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0900 - val_acc: 0.9902\n",
      "Epoch 128/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0041 - acc: 0.9986 - val_loss: 0.0959 - val_acc: 0.9909\n",
      "Epoch 129/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0956 - val_acc: 0.9905\n",
      "Epoch 130/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0976 - val_acc: 0.9904\n",
      "Epoch 131/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.1000 - val_acc: 0.9910\n",
      "Epoch 132/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0966 - val_acc: 0.9912\n",
      "Epoch 133/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0987 - val_acc: 0.9916\n",
      "Epoch 134/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0933 - val_acc: 0.9902\n",
      "Epoch 135/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0039 - acc: 0.9987 - val_loss: 0.0951 - val_acc: 0.9906\n",
      "Epoch 136/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0938 - val_acc: 0.9902\n",
      "Epoch 137/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0938 - val_acc: 0.9908\n",
      "Epoch 138/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0946 - val_acc: 0.9905\n",
      "Epoch 139/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0925 - val_acc: 0.9896\n",
      "Epoch 140/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0895 - val_acc: 0.9898\n",
      "Epoch 141/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.0995 - val_acc: 0.9910\n",
      "Epoch 142/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0974 - val_acc: 0.9911\n",
      "Epoch 143/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0985 - val_acc: 0.9907\n",
      "Epoch 144/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0989 - val_acc: 0.9911\n",
      "Epoch 145/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0998 - val_acc: 0.9899\n",
      "Epoch 146/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.1014 - val_acc: 0.9909\n",
      "Epoch 147/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0978 - val_acc: 0.9904\n",
      "Epoch 148/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0995 - val_acc: 0.9908\n",
      "Epoch 149/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.1047 - val_acc: 0.9903\n",
      "Epoch 150/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0976 - val_acc: 0.9906\n",
      "Epoch 151/200\n",
      "46370/46370 [==============================] - 75s 2ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.1028 - val_acc: 0.9907\n",
      "Epoch 152/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0975 - val_acc: 0.9908\n",
      "Epoch 153/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0985 - val_acc: 0.9909\n",
      "Epoch 154/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0959 - val_acc: 0.9908\n",
      "Epoch 155/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.1020 - val_acc: 0.9909\n",
      "Epoch 156/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0989 - val_acc: 0.9909\n",
      "Epoch 157/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0972 - val_acc: 0.9907\n",
      "Epoch 158/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0924 - val_acc: 0.9904\n",
      "Epoch 159/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0992 - val_acc: 0.9911\n",
      "Epoch 160/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0970 - val_acc: 0.9904\n",
      "Epoch 161/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0954 - val_acc: 0.9908\n",
      "Epoch 162/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0926 - val_acc: 0.9901\n",
      "Epoch 163/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0978 - val_acc: 0.9901\n",
      "Epoch 164/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.1007 - val_acc: 0.9909\n",
      "Epoch 165/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0969 - val_acc: 0.9908\n",
      "Epoch 166/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0962 - val_acc: 0.9907\n",
      "Epoch 167/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0966 - val_acc: 0.9906\n",
      "Epoch 168/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0996 - val_acc: 0.9911\n",
      "Epoch 169/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.1024 - val_acc: 0.9900\n",
      "Epoch 170/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.0997 - val_acc: 0.9909\n",
      "Epoch 171/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0948 - val_acc: 0.9912\n",
      "Epoch 172/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0951 - val_acc: 0.9907\n",
      "Epoch 173/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.1029 - val_acc: 0.9906\n",
      "Epoch 174/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0955 - val_acc: 0.9906\n",
      "Epoch 175/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1021 - val_acc: 0.9909\n",
      "Epoch 176/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1023 - val_acc: 0.9908\n",
      "Epoch 177/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1013 - val_acc: 0.9905\n",
      "Epoch 178/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1091 - val_acc: 0.9908\n",
      "Epoch 179/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1004 - val_acc: 0.9902\n",
      "Epoch 180/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0981 - val_acc: 0.9907\n",
      "Epoch 181/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1001 - val_acc: 0.9904\n",
      "Epoch 182/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1020 - val_acc: 0.9903\n",
      "Epoch 183/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0962 - val_acc: 0.9907\n",
      "Epoch 184/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1004 - val_acc: 0.9904\n",
      "Epoch 185/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0978 - val_acc: 0.9906\n",
      "Epoch 186/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0978 - val_acc: 0.9906\n",
      "Epoch 187/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1005 - val_acc: 0.9907\n",
      "Epoch 188/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1014 - val_acc: 0.9911\n",
      "Epoch 189/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0993 - val_acc: 0.9905\n",
      "Epoch 190/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1009 - val_acc: 0.9902\n",
      "Epoch 191/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1032 - val_acc: 0.9904\n",
      "Epoch 192/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1021 - val_acc: 0.9907\n",
      "Epoch 193/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1027 - val_acc: 0.9909\n",
      "Epoch 194/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0970 - val_acc: 0.9904\n",
      "Epoch 195/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1022 - val_acc: 0.9910\n",
      "Epoch 196/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1066 - val_acc: 0.9912\n",
      "Epoch 197/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.1021 - val_acc: 0.9910\n",
      "Epoch 198/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1045 - val_acc: 0.9904\n",
      "Epoch 199/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1035 - val_acc: 0.9912\n",
      "Epoch 200/200\n",
      "46370/46370 [==============================] - 74s 2ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1092 - val_acc: 0.9907\n"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module generates notes for a midi file using the\n",
    "    trained neural network \"\"\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import instrument, note, stream, chord, pitch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "\n",
    "sequence_length = 40\n",
    "def get_notes(folder=\"chopin\"):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = np.array([])\n",
    "\n",
    "    for file in glob.glob(\"{}/*.mid\".format(folder)):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        notes_dict = {}\n",
    "        max_offset = 0\n",
    "        for element in notes_to_parse:        \n",
    "            if isinstance(element, note.Note) or isinstance(element, chord.Chord):  \n",
    "                if element.offset not in notes_dict:\n",
    "                    notes_dict[element.offset] = []\n",
    "                notes_dict[element.offset].append(element)\n",
    "                max_offset = element.offset    \n",
    "        ret = merge_notes(notes_dict, max_offset)\n",
    "        #print(len(ret))\n",
    "        notes = np.append(notes, ret)\n",
    "        #print(len(notes))\n",
    "    row = notes.size / 88\n",
    "    notes = notes.reshape(int(row), 88)\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes\n",
    "\n",
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    #with open('data/notes', 'rb') as filepath:\n",
    "    #    notes = pickle.load(filepath)\n",
    "    \n",
    "    network_input = prepare_sequences(get_notes())\n",
    "    for i in range(5):\n",
    "        # pick a random sequence from the input as a starting point for the prediction\n",
    "        start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "        arr = {1,50,100,152,191}\n",
    "        for i in arr:\n",
    "            model = create_network(i)\n",
    "            prediction_output = generate_notes(model, network_input, start)\n",
    "            create_midi(prediction_output, i)\n",
    "\n",
    "def prepare_sequences(notes):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    \n",
    "    network_input = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append(sequence_in)\n",
    "\n",
    "    return network_input\n",
    "\n",
    "def create_network(i):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(sequence_length, 88),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(88))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    # Load the weights to each node\n",
    "    if i == 1:\n",
    "        model.load_weights('weights-improvement-01-0.0808-bigger.hdf5')\n",
    "    elif i == 50:\n",
    "        model.load_weights('weights-improvement-50-0.0109-bigger.hdf5')\n",
    "    elif i == 100:\n",
    "        model.load_weights('weights-improvement-100-0.0050-bigger.hdf5')\n",
    "    elif i == 152:\n",
    "        model.load_weights('weights-improvement-152-0.0035-bigger.hdf5')\n",
    "    else:\n",
    "        model.load_weights('weights-improvement-191-0.0029-bigger.hdf5')\n",
    "    return model\n",
    "\n",
    "def generate_notes(model, network_input, start):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    \n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    threshold = 0.5\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, sequence_length, 88))\n",
    "        prediction = model.predict(prediction_input, verbose=0)[0]\n",
    "        prediction[prediction > threshold] = 1\n",
    "        prediction[prediction <= threshold] = 0   \n",
    "        pattern = np.append(pattern, prediction)[88:]    \n",
    "        #print(prediction)\n",
    "        prediction_output.append(prediction)\n",
    "    return prediction_output\n",
    "\n",
    "import time\n",
    "current_time = lambda: int(round(time.time()))\n",
    "\n",
    "def create_midi(prediction_output, i):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    #print(prediction_output)\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        indices = np.where(pattern > 0)[0]\n",
    "        if len(indices) > 0:\n",
    "            notes = []\n",
    "            for index in indices:\n",
    "                n = note.Note()\n",
    "                p = pitch.Pitch()\n",
    "                p.midi = index + 21\n",
    "                n.pitch = p\n",
    "                n.storedInstrument = instrument.Piano()\n",
    "                notes.append(n)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "       \n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.25\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='output/40_sentence_test_output_%d_%s.mid' %(i, current_time()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chopin/fruehlingsrauschen_format0.mid\n",
      "Parsing chopin/chpn_op23.mid\n",
      "Parsing chopin/chpn-p19.mid\n",
      "Parsing chopin/chpn_op7_2.mid\n",
      "Parsing chopin/chpn-p18.mid\n",
      "Parsing chopin/chpn-p24.mid\n",
      "Parsing chopin/grieg_kobold.mid\n",
      "Parsing chopin/clementi_opus36_5_2_format0.mid\n",
      "Parsing chopin/chpn_op7_1.mid\n",
      "Parsing chopin/gra_esp_4.mid\n",
      "Parsing chopin/clementi_opus36_1_2_format0.mid\n",
      "Parsing chopin/clementi_opus36_6_2_format0.mid\n",
      "Parsing chopin/chpn-p23.mid\n",
      "Parsing chopin/chpn-p9.mid\n",
      "Parsing chopin/clementi_opus36_2_2_format0.mid\n",
      "Parsing chopin/chpn-p8.mid\n",
      "Parsing chopin/chpn-p22.mid\n",
      "Parsing chopin/chpn-p20.mid\n",
      "Parsing chopin/gra_esp_2.mid\n",
      "Parsing chopin/gra_esp_3.mid\n",
      "Parsing chopin/grieg_halling.mid\n",
      "Parsing chopin/chpn-p21.mid\n",
      "Parsing chopin/chp_op18.mid\n",
      "Parsing chopin/chpn_op35_4.mid\n",
      "Parsing chopin/grieg_waechter.mid\n",
      "Parsing chopin/clementi_opus36_4_3_format0.mid\n",
      "Parsing chopin/god_chpn_op10_e01_format0.mid\n",
      "Parsing chopin/chpn_op33_2.mid\n",
      "Parsing chopin/chp_op31.mid\n",
      "Parsing chopin/deb_prel.mid\n",
      "Parsing chopin/chpn_op25_e4.mid\n",
      "Parsing chopin/clementi_opus36_2_1_format0.mid\n",
      "Parsing chopin/clementi_opus36_6_1_format0.mid\n",
      "Parsing chopin/chpn_op35_2.mid\n",
      "Parsing chopin/grieg_walzer.mid\n",
      "Parsing chopin/clementi_opus36_1_1_format0.mid\n",
      "Parsing chopin/chpn_op25_e1.mid\n",
      "Parsing chopin/grieg_butterfly.mid\n",
      "Parsing chopin/chpn_op33_4.mid\n",
      "Parsing chopin/chpn_op53.mid\n",
      "Parsing chopin/elise.mid\n",
      "Parsing chopin/chpn_op35_3.mid\n",
      "Parsing chopin/clementi_opus36_5_1_format0.mid\n",
      "Parsing chopin/chpn_op35_1.mid\n",
      "Parsing chopin/chpn_op25_e2.mid\n",
      "Parsing chopin/grieg_wanderer.mid\n",
      "Parsing chopin/chpn_op25_e3.mid\n",
      "Parsing chopin/clementi_opus36_3_3_format0.mid\n",
      "Parsing chopin/clementi_opus36_4_1_format0.mid\n",
      "Parsing chopin/grieg_album.mid\n",
      "Parsing chopin/grieg_voeglein.mid\n",
      "Parsing chopin/grieg_spring.mid\n",
      "Parsing chopin/chpn_op10_e12.mid\n",
      "Parsing chopin/grieg_berceuse.mid\n",
      "Parsing chopin/clementi_opus36_2_3_format0.mid\n",
      "Parsing chopin/grieg_brooklet.mid\n",
      "Parsing chopin/chpn_op10_e05.mid\n",
      "Parsing chopin/grieg_once_upon_a_time.mid\n",
      "Parsing chopin/clementi_opus36_1_3_format0.mid\n",
      "Parsing chopin/chpn_op10_e01.mid\n",
      "Parsing chopin/example_song.mid\n",
      "Parsing chopin/clementi_opus36_5_3_format0.mid\n",
      "Parsing chopin/chpn_op66.mid\n",
      "Parsing chopin/grieg_march.mid\n",
      "Parsing chopin/clementi_opus36_3_1_format0.mid\n",
      "Parsing chopin/grieg_zwerge.mid\n",
      "Parsing chopin/god_alb_esp2_format0.mid\n",
      "Parsing chopin/chpn-p10.mid\n",
      "Parsing chopin/chpn_op25_e12.mid\n",
      "Parsing chopin/clementi_opus36_3_2_format0.mid\n",
      "Parsing chopin/chpn-p6.mid\n",
      "Parsing chopin/chpn-p7.mid\n",
      "Parsing chopin/debussy_cc_6.mid\n",
      "Parsing chopin/chpn-p11.mid\n",
      "Parsing chopin/grieg_wedding.mid\n",
      "Parsing chopin/chpn-p13.mid\n",
      "Parsing chopin/debussy_cc_4.mid\n",
      "Parsing chopin/chpn_op25_e11.mid\n",
      "Parsing chopin/chpn-p5.mid\n",
      "Parsing chopin/chpn-p4.mid\n",
      "Parsing chopin/deb_menu.mid\n",
      "Parsing chopin/chpn-p12.mid\n",
      "Parsing chopin/debussy_cc_1.mid\n",
      "Parsing chopin/chpn-p16.mid\n",
      "Parsing chopin/chpn_op27_2.mid\n",
      "Parsing chopin/chpn-p1.mid\n",
      "Parsing chopin/chpn-p17.mid\n",
      "Parsing chopin/debussy_cc_2.mid\n",
      "Parsing chopin/chpn-p15.mid\n",
      "Parsing chopin/chpn-p3.mid\n",
      "Parsing chopin/chpn_op27_1.mid\n",
      "Parsing chopin/chpn-p2.mid\n",
      "Parsing chopin/grieg_elfentanz.mid\n",
      "Parsing chopin/chpn-p14.mid\n",
      "Parsing chopin/debussy_cc_3.mid\n",
      "Parsing chopin/clementi_opus36_4_2_format0.mid\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
