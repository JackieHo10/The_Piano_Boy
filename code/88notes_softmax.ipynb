{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import converter, instrument, note, chord\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_network():\n",
    "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
    "    notes = get_notes(\"chopin\")\n",
    "\n",
    "    network_input, network_output = prepare_sequences(notes)\n",
    "\n",
    "    model = create_network(network_input)\n",
    "\n",
    "    train(model, network_input, network_output)\n",
    "    \n",
    "    \n",
    "def merge_notes(notes_dict, max_offset):\n",
    "            \n",
    "    ret = np.array([])\n",
    "    for i in np.arange(0, max_offset, 0.5):\n",
    "        pitches = np.zeros(88)\n",
    "        if i in notes_dict:            \n",
    "            for element in notes_dict[i]:            \n",
    "                if isinstance(element, note.Note):\n",
    "                    pitches[element.pitch.midi-21] = 1\n",
    "                else:\n",
    "                    for p in element.pitches:\n",
    "                        pitches[p.midi-21] = 1    \n",
    "        ret = np.append(ret, pitches)\n",
    "    return ret\n",
    "    \n",
    "\n",
    "def get_notes(folder=\"midi_songs\"):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = np.array([])\n",
    "\n",
    "    for file in glob.glob(\"{}/*.mid\".format(folder)):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        notes_dict = {}\n",
    "        max_offset = 0\n",
    "        for element in notes_to_parse:        \n",
    "            if isinstance(element, note.Note) or isinstance(element, chord.Chord):  \n",
    "                if element.offset not in notes_dict:\n",
    "                    notes_dict[element.offset] = []\n",
    "                notes_dict[element.offset].append(element)\n",
    "                max_offset = element.offset    \n",
    "        ret = merge_notes(notes_dict, max_offset)\n",
    "        #print(len(ret))\n",
    "        notes = np.append(notes, ret)\n",
    "        #print(len(notes))\n",
    "    row = notes.size / 88\n",
    "    notes = notes.reshape(int(row), 88)\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes\n",
    "\n",
    "def prepare_sequences(notes):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append(sequence_in)\n",
    "        network_output.append(sequence_out)\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    #print(n_patterns)\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 88))\n",
    "    network_output = np.reshape(network_output, (n_patterns, 88))\n",
    "    return (network_input, network_output)\n",
    "\n",
    "def create_network(network_input):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(88))\n",
    "    #model.add(Activation('sigmoid'))\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "    #print(network_input.shape)\n",
    "    #print(network_output.shape)\n",
    "    model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n = get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing chopin/chpn-p16.mid\n",
      "Parsing chopin/chpn_op35_1.mid\n",
      "Parsing chopin/chpn_op25_e4.mid\n",
      "Parsing chopin/chpn-p10.mid\n",
      "Parsing chopin/deb_prel.mid\n",
      "Parsing chopin/clementi_opus36_5_2_format0.mid\n",
      "Parsing chopin/chpn-p20.mid\n",
      "Parsing chopin/chpn_op25_e1.mid\n",
      "Parsing chopin/chpn-p14.mid\n",
      "Parsing chopin/grieg_halling.mid\n",
      "Parsing chopin/grieg_brooklet.mid\n",
      "Parsing chopin/chpn-p4.mid\n",
      "Parsing chopin/chpn-p13.mid\n",
      "Parsing chopin/grieg_kobold.mid\n",
      "Parsing chopin/chpn-p6.mid\n",
      "Parsing chopin/grieg_elfentanz.mid\n",
      "Parsing chopin/clementi_opus36_4_3_format0.mid\n",
      "Parsing chopin/clementi_opus36_5_3_format0.mid\n",
      "Parsing chopin/chpn-p3.mid\n",
      "Parsing chopin/clementi_opus36_6_1_format0.mid\n",
      "Parsing chopin/chpn-p15.mid\n",
      "Parsing chopin/chpn_op35_4.mid\n",
      "Parsing chopin/chpn_op35_3.mid\n",
      "Parsing chopin/god_alb_esp2_format0.mid\n",
      "Parsing chopin/fruehlingsrauschen_format0.mid\n",
      "Parsing chopin/chpn-p8.mid\n",
      "Parsing chopin/debussy_cc_2.mid\n",
      "Parsing chopin/debussy_cc_3.mid\n",
      "Parsing chopin/chpn_op10_e05.mid\n",
      "Parsing chopin/elise.mid\n",
      "Parsing chopin/grieg_waechter.mid\n",
      "Parsing chopin/gra_esp_3.mid\n",
      "Parsing chopin/debussy_cc_1.mid\n",
      "Parsing chopin/grieg_album.mid\n",
      "Parsing chopin/clementi_opus36_1_2_format0.mid\n",
      "Parsing chopin/chpn-p5.mid\n",
      "Parsing chopin/grieg_spring.mid\n",
      "Parsing chopin/chpn-p21.mid\n",
      "Parsing chopin/chpn_op53.mid\n",
      "Parsing chopin/chpn-p12.mid\n",
      "Parsing chopin/chpn_op7_2.mid\n",
      "Parsing chopin/clementi_opus36_1_1_format0.mid\n",
      "Parsing chopin/grieg_walzer.mid\n",
      "Parsing chopin/grieg_zwerge.mid\n",
      "Parsing chopin/chpn_op27_2.mid\n",
      "Parsing chopin/clementi_opus36_2_2_format0.mid\n",
      "Parsing chopin/clementi_opus36_3_3_format0.mid\n",
      "Parsing chopin/grieg_voeglein.mid\n",
      "Parsing chopin/chpn_op7_1.mid\n",
      "Parsing chopin/clementi_opus36_6_2_format0.mid\n",
      "Parsing chopin/chpn-p7.mid\n",
      "Parsing chopin/chpn_op27_1.mid\n",
      "Parsing chopin/chpn_op25_e11.mid\n",
      "Parsing chopin/grieg_wedding.mid\n",
      "Parsing chopin/example_song.mid\n",
      "Parsing chopin/clementi_opus36_3_2_format0.mid\n",
      "Parsing chopin/clementi_opus36_4_1_format0.mid\n",
      "Parsing chopin/chpn_op33_4.mid\n",
      "Parsing chopin/chpn_op33_2.mid\n",
      "Parsing chopin/chp_op18.mid\n",
      "Parsing chopin/clementi_opus36_2_3_format0.mid\n",
      "Parsing chopin/chpn_op10_e12.mid\n",
      "Parsing chopin/chpn_op66.mid\n",
      "Parsing chopin/clementi_opus36_5_1_format0.mid\n",
      "Parsing chopin/chpn_op23.mid\n",
      "Parsing chopin/chpn_op25_e3.mid\n",
      "Parsing chopin/clementi_opus36_2_1_format0.mid\n",
      "Parsing chopin/grieg_wanderer.mid\n",
      "Parsing chopin/gra_esp_2.mid\n",
      "Parsing chopin/chpn_op25_e2.mid\n",
      "Parsing chopin/debussy_cc_6.mid\n",
      "Parsing chopin/clementi_opus36_4_2_format0.mid\n",
      "Parsing chopin/chpn-p24.mid\n",
      "Parsing chopin/clementi_opus36_3_1_format0.mid\n",
      "Parsing chopin/chpn-p18.mid\n",
      "Parsing chopin/chpn-p22.mid\n",
      "Parsing chopin/grieg_butterfly.mid\n",
      "Parsing chopin/deb_menu.mid\n",
      "Parsing chopin/chpn-p19.mid\n",
      "Parsing chopin/chpn-p9.mid\n",
      "Parsing chopin/chpn_op25_e12.mid\n",
      "Parsing chopin/chpn-p23.mid\n",
      "Parsing chopin/chpn-p17.mid\n",
      "Parsing chopin/clementi_opus36_1_3_format0.mid\n",
      "Parsing chopin/chpn-p2.mid\n",
      "Parsing chopin/grieg_once_upon_a_time.mid\n",
      "Parsing chopin/chpn-p1.mid\n",
      "Parsing chopin/chpn-p11.mid\n",
      "Parsing chopin/grieg_berceuse.mid\n",
      "Parsing chopin/chpn_op10_e01.mid\n",
      "Parsing chopin/chp_op31.mid\n",
      "Parsing chopin/debussy_cc_4.mid\n",
      "Parsing chopin/grieg_march.mid\n",
      "Parsing chopin/gra_esp_4.mid\n",
      "Parsing chopin/chpn_op35_2.mid\n",
      "Parsing chopin/god_chpn_op10_e01_format0.mid\n",
      "Epoch 1/200\n",
      "58226/58226 [==============================] - 217s 4ms/step - loss: 7.4472\n",
      "Epoch 2/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 6.8483\n",
      "Epoch 3/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 6.4720\n",
      "Epoch 4/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 6.2662\n",
      "Epoch 5/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 6.0324\n",
      "Epoch 6/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 5.7834\n",
      "Epoch 7/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 5.5451\n",
      "Epoch 8/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 5.2799\n",
      "Epoch 9/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 5.0330\n",
      "Epoch 10/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 4.7898\n",
      "Epoch 11/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 4.5712\n",
      "Epoch 12/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 4.3765\n",
      "Epoch 13/200\n",
      "58226/58226 [==============================] - 215s 4ms/step - loss: 4.2057\n",
      "Epoch 14/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 4.0599\n",
      "Epoch 15/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.9370\n",
      "Epoch 16/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.8271\n",
      "Epoch 17/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.7304\n",
      "Epoch 18/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.6435\n",
      "Epoch 19/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.5590\n",
      "Epoch 20/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.4908\n",
      "Epoch 21/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.4292\n",
      "Epoch 22/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.3675\n",
      "Epoch 23/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.3240\n",
      "Epoch 24/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.2734\n",
      "Epoch 25/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.2317\n",
      "Epoch 26/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.1880\n",
      "Epoch 27/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.1576\n",
      "Epoch 28/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.1228\n",
      "Epoch 29/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.0900\n",
      "Epoch 30/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.0589\n",
      "Epoch 31/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.0344\n",
      "Epoch 32/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 3.0178\n",
      "Epoch 33/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.9904\n",
      "Epoch 34/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.9658\n",
      "Epoch 35/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.9465\n",
      "Epoch 36/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.9260\n",
      "Epoch 37/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.9101\n",
      "Epoch 38/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8939\n",
      "Epoch 39/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8776\n",
      "Epoch 40/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8600\n",
      "Epoch 41/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8524\n",
      "Epoch 42/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8335\n",
      "Epoch 43/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8231\n",
      "Epoch 44/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8070\n",
      "Epoch 45/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.8052\n",
      "Epoch 46/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7838\n",
      "Epoch 47/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7719\n",
      "Epoch 48/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7669\n",
      "Epoch 49/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7584\n",
      "Epoch 50/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7474\n",
      "Epoch 51/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7399\n",
      "Epoch 52/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7307\n",
      "Epoch 53/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7257\n",
      "Epoch 54/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7150\n",
      "Epoch 55/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7055\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.7039\n",
      "Epoch 57/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6895\n",
      "Epoch 58/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6870\n",
      "Epoch 59/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6781\n",
      "Epoch 60/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6712\n",
      "Epoch 61/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6663\n",
      "Epoch 62/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6582\n",
      "Epoch 63/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6569\n",
      "Epoch 64/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6466\n",
      "Epoch 65/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.6406\n",
      "Epoch 66/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6339\n",
      "Epoch 67/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6329\n",
      "Epoch 68/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6288\n",
      "Epoch 69/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6225\n",
      "Epoch 70/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.6175\n",
      "Epoch 71/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.6078\n",
      "Epoch 72/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6082\n",
      "Epoch 73/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.6034\n",
      "Epoch 74/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.6004\n",
      "Epoch 75/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5939\n",
      "Epoch 76/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5934\n",
      "Epoch 77/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5865\n",
      "Epoch 78/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5820\n",
      "Epoch 79/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5816\n",
      "Epoch 80/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5698\n",
      "Epoch 81/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5720\n",
      "Epoch 82/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5678\n",
      "Epoch 83/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5675\n",
      "Epoch 84/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5642\n",
      "Epoch 85/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5565\n",
      "Epoch 86/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5569\n",
      "Epoch 87/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5482\n",
      "Epoch 88/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5482\n",
      "Epoch 89/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5474\n",
      "Epoch 90/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5416\n",
      "Epoch 91/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5409\n",
      "Epoch 92/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5318\n",
      "Epoch 93/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.5364\n",
      "Epoch 94/200\n",
      "58226/58226 [==============================] - 215s 4ms/step - loss: 2.5319\n",
      "Epoch 95/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5285\n",
      "Epoch 96/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5238\n",
      "Epoch 97/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5272\n",
      "Epoch 98/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5213\n",
      "Epoch 99/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5185\n",
      "Epoch 100/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5110\n",
      "Epoch 101/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5153\n",
      "Epoch 102/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5119\n",
      "Epoch 103/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5084\n",
      "Epoch 104/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5103\n",
      "Epoch 105/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5020\n",
      "Epoch 106/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.5055\n",
      "Epoch 107/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4996\n",
      "Epoch 108/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4956\n",
      "Epoch 109/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4949\n",
      "Epoch 110/200\n",
      "58226/58226 [==============================] - 215s 4ms/step - loss: 2.4921\n",
      "Epoch 111/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4947\n",
      "Epoch 112/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4896\n",
      "Epoch 113/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4883\n",
      "Epoch 114/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4867\n",
      "Epoch 115/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4907\n",
      "Epoch 116/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4873\n",
      "Epoch 117/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4846\n",
      "Epoch 118/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4799\n",
      "Epoch 119/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4758\n",
      "Epoch 120/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4732\n",
      "Epoch 121/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4741\n",
      "Epoch 122/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4739\n",
      "Epoch 123/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4724\n",
      "Epoch 124/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4689\n",
      "Epoch 125/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4676\n",
      "Epoch 126/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4654\n",
      "Epoch 127/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4679\n",
      "Epoch 128/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4593\n",
      "Epoch 129/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4606\n",
      "Epoch 130/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4596\n",
      "Epoch 131/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4550\n",
      "Epoch 132/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4532\n",
      "Epoch 133/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4584\n",
      "Epoch 134/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4560\n",
      "Epoch 135/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4537\n",
      "Epoch 136/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4493\n",
      "Epoch 137/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4525\n",
      "Epoch 138/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4448\n",
      "Epoch 139/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4487\n",
      "Epoch 140/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4448\n",
      "Epoch 141/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4470\n",
      "Epoch 142/200\n",
      "58226/58226 [==============================] - 217s 4ms/step - loss: 2.4414\n",
      "Epoch 143/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4374\n",
      "Epoch 144/200\n",
      "58226/58226 [==============================] - 215s 4ms/step - loss: 2.4408\n",
      "Epoch 145/200\n",
      "58226/58226 [==============================] - 216s 4ms/step - loss: 2.4397\n",
      "Epoch 146/200\n",
      "58226/58226 [==============================] - 214s 4ms/step - loss: 2.4381\n",
      "Epoch 147/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58226/58226 [==============================] - 217s 4ms/step - loss: 2.4348\n",
      "Epoch 148/200\n",
      "58226/58226 [==============================] - 216s 4ms/step - loss: 2.4362\n",
      "Epoch 149/200\n",
      "58226/58226 [==============================] - 216s 4ms/step - loss: 2.4330\n",
      "Epoch 150/200\n",
      "58226/58226 [==============================] - 216s 4ms/step - loss: 2.4308\n",
      "Epoch 151/200\n",
      "58226/58226 [==============================] - 217s 4ms/step - loss: 2.4329\n",
      "Epoch 152/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.4315\n",
      "Epoch 153/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4291\n",
      "Epoch 154/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.4312\n",
      "Epoch 155/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4245\n",
      "Epoch 156/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4272\n",
      "Epoch 157/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4262\n",
      "Epoch 158/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4303\n",
      "Epoch 159/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4211\n",
      "Epoch 160/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4235\n",
      "Epoch 161/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4173\n",
      "Epoch 162/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4170\n",
      "Epoch 163/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4196\n",
      "Epoch 164/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4169\n",
      "Epoch 165/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4145\n",
      "Epoch 166/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4142\n",
      "Epoch 167/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4165\n",
      "Epoch 168/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4141\n",
      "Epoch 169/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4097\n",
      "Epoch 170/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4053\n",
      "Epoch 171/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4091\n",
      "Epoch 172/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4107\n",
      "Epoch 173/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4154\n",
      "Epoch 174/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.4063\n",
      "Epoch 175/200\n",
      "58226/58226 [==============================] - 213s 4ms/step - loss: 2.4073\n",
      "Epoch 176/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4049\n",
      "Epoch 177/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4045\n",
      "Epoch 178/200\n",
      "58226/58226 [==============================] - 212s 4ms/step - loss: 2.4058\n",
      "Epoch 179/200\n",
      "52864/58226 [==========================>...] - ETA: 19s - loss: 2.4005"
     ]
    }
   ],
   "source": [
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This module generates notes for a midi file using the\n",
    "    trained neural network \"\"\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import instrument, note, stream, chord, pitch\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "\n",
    "sequence_length = 100\n",
    "def get_notes(folder=\"test\"):\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = np.array([])\n",
    "\n",
    "    for file in glob.glob(\"{}/*.mid\".format(folder)):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(midi)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        notes_dict = {}\n",
    "        max_offset = 0\n",
    "        for element in notes_to_parse:        \n",
    "            if isinstance(element, note.Note) or isinstance(element, chord.Chord):  \n",
    "                if element.offset not in notes_dict:\n",
    "                    notes_dict[element.offset] = []\n",
    "                notes_dict[element.offset].append(element)\n",
    "                max_offset = element.offset    \n",
    "        ret = merge_notes(notes_dict, max_offset)\n",
    "        #print(len(ret))\n",
    "        notes = np.append(notes, ret)\n",
    "        #print(len(notes))\n",
    "    row = notes.size / 88\n",
    "    notes = notes.reshape(int(row), 88)\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    \n",
    "    return notes\n",
    "\n",
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    #with open('data/notes', 'rb') as filepath:\n",
    "    #    notes = pickle.load(filepath)\n",
    "\n",
    "    network_input = prepare_sequences(get_notes())\n",
    "    model = create_network()\n",
    "    prediction_output = generate_notes(model, network_input)\n",
    "    create_midi(prediction_output)\n",
    "\n",
    "def prepare_sequences(notes):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    \n",
    "    network_input = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append(sequence_in)\n",
    "\n",
    "    return network_input\n",
    "\n",
    "def create_network():\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        512,\n",
    "        input_shape=(sequence_length, 88),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(88))\n",
    "    #model.add(Activation('sigmoid'))\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    # Load the weights to each node\n",
    "    model.load_weights('weights-improvement-195-1.4606-bigger.hdf5')\n",
    "    return model\n",
    "\n",
    "def generate_notes(model, network_input):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "    threshold = 0.5\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, sequence_length, 88))\n",
    "        prediction = model.predict(prediction_input, verbose=0)[0]\n",
    "        index = np.argmax(prediction)\n",
    "        prediction = np.zeros(88)\n",
    "        prediction[index] = 1\n",
    "        pattern = np.append(pattern, prediction)[88:]    \n",
    "        #print(prediction)\n",
    "        prediction_output.append(prediction)\n",
    "    return prediction_output\n",
    "\n",
    "import time\n",
    "current_time = lambda: int(round(time.time()))\n",
    "\n",
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "    #print(prediction_output)\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        indices = np.where(pattern > 0)[0]\n",
    "        if len(indices) > 0:\n",
    "            notes = []\n",
    "            for index in indices:\n",
    "                n = note.Note()\n",
    "                p = pitch.Pitch()\n",
    "                p.midi = index + 21\n",
    "                n.pitch = p\n",
    "                n.storedInstrument = instrument.Piano()\n",
    "                notes.append(n)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "       \n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "\n",
    "    midi_stream.write('midi', fp='40_sentence_05_test_output_{}.mid'.format(current_time()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n",
      "Parsing test/chpn_op25_e4.mid\n",
      "Parsing test/chpn_op25_e1.mid\n",
      "Parsing test/chpn_op25_e3.mid\n",
      "Parsing test/chpn_op25_e2.mid\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
